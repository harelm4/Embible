# Embible

## Analyze The Results For Fine-Tuning To several Bert models.

We trained all the models for: 10,20 and 50 epochs with trying different parameters: batch size, learning rate, weight decay

<!-- TABLE_GENERATE_START -->

| Models  | Second Header |
| ------------- | ------------- |
|DistilBert  
|DistilBert  |
|DistilBert  |
|Mbert       |
|Mbert       |
|Mbert       |
|tavBert     |
|tavBert     |
|tavBert     |
|Aleph-Bert-gimel |
|Aleph-Bert-gimel |
|Aleph-Bert-gimel |

<!-- TABLE_GENERATE_END -->


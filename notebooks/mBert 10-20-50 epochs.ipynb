{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca793c9-e351-4d62-92df-a97ff44f49a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./.local/lib/python3.7/site-packages (2.8.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.conda/envs/my_env/lib/python3.7/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in ./.local/lib/python3.7/site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in ./.conda/envs/my_env/lib/python3.7/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: dill<0.3.7 in ./.local/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.conda/envs/my_env/lib/python3.7/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.7/site-packages (from datasets) (3.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.conda/envs/my_env/lib/python3.7/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in ./.conda/envs/my_env/lib/python3.7/site-packages (from datasets) (5.2.0)\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.7/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: responses<0.19 in ./.local/lib/python3.7/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in ./.local/lib/python3.7/site-packages (from datasets) (0.11.1)\n",
      "Requirement already satisfied: packaging in ./.conda/envs/my_env/lib/python3.7/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pandas in ./.conda/envs/my_env/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.7/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.conda/envs/my_env/lib/python3.7/site-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.local/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.7/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/envs/my_env/lib/python3.7/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in ./.local/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in ./.conda/envs/my_env/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in ./.conda/envs/my_env/lib/python3.7/site-packages (from aiohttp->datasets) (4.4.0)\n",
      "Requirement already satisfied: filelock in ./.conda/envs/my_env/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/my_env/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/envs/my_env/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/my_env/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.conda/envs/my_env/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./.conda/envs/my_env/lib/python3.7/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./.conda/envs/my_env/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/envs/my_env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.7/site-packages (4.25.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in ./.local/lib/python3.7/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.conda/envs/my_env/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in ./.conda/envs/my_env/lib/python3.7/site-packages (from transformers) (5.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.conda/envs/my_env/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.local/lib/python3.7/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.conda/envs/my_env/lib/python3.7/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: filelock in ./.conda/envs/my_env/lib/python3.7/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/envs/my_env/lib/python3.7/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: requests in ./.conda/envs/my_env/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.conda/envs/my_env/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.conda/envs/my_env/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.conda/envs/my_env/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/my_env/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/my_env/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/envs/my_env/lib/python3.7/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.conda/envs/my_env/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.local/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.local/lib/python3.7/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.local/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.local/lib/python3.7/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/envs/my_env/lib/python3.7/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: wheel in ./.conda/envs/my_env/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in ./.conda/envs/my_env/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1901a75-f9da-4537-9776-fe0a636a8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851fcbd8-19a0-426a-96b0-4583f4ca4d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForMaskedLM\n",
    "cp = \"bert-base-multilingual-uncased\"\n",
    "model=AutoModelForMaskedLM.from_pretrained(cp)\n",
    "tokenizer=AutoTokenizer.from_pretrained(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9579701f-9e27-461a-bf9b-97ea0938e982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-66d144cf64d2204f\n",
      "Found cached dataset csv (/home/eldark/.cache/huggingface/datasets/csv/default-66d144cf64d2204f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f647a0fdc6f5418da86c8565ecc64de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-37505e917a9305ac\n",
      "Found cached dataset csv (/home/eldark/.cache/huggingface/datasets/csv/default-37505e917a9305ac/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4385778ea204459999d1939be4e0c459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "ds=datasets.load_dataset(\"csv\", data_files='train_df_no_niqqud.csv',sep=\"\\t\")\n",
    "dsv=datasets.load_dataset(\"csv\", data_files='valid_df_no_niqqud.csv',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ec7572-489f-48d7-9ac1-411fd90a7a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/eldark/.cache/huggingface/datasets/csv/default-66d144cf64d2204f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-e4ddd62cffd0a70a.arrow\n",
      "Loading cached processed dataset at /home/eldark/.cache/huggingface/datasets/csv/default-37505e917a9305ac/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-0125161d0e5aee94.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(dataset):\n",
    "  return tokenizer(str(dataset[\"verse\"])\n",
    "                      )\n",
    "\n",
    "tokenized_ds=ds.map(tokenize_function)\n",
    "tokenized_dsv=dsv.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381c983c-9bae-435c-9fe0-f226e9470fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c6bed47-a3dc-4704-91da-d40d525f5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(ds[\"train\"])\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"Models/Embibert-finetuned-mBert-50-epochs\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=2e-6,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    push_to_hub=False,\n",
    "    logging_steps=logging_steps,\n",
    "    num_train_epochs=50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55614b1e-87bf-44fc-9398-3d1e6cd3496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_ds['train'],\n",
    "    eval_dataset=tokenized_dsv,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b1fd9c-50e6-4520-838a-135f2a5eeb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7aa3518-d0a4-4464-acef-e740460bfd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the GPU available? True\n"
     ]
    }
   ],
   "source": [
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8bd1b09-f733-43e5-96c0-29add16c611c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "/home/eldark/.local/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 22144\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69200\n",
      "  Number of trainable parameters = 167463831\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69200' max='69200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69200/69200 5:32:34, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.129500</td>\n",
       "      <td>2.997658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.909300</td>\n",
       "      <td>2.753987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.823500</td>\n",
       "      <td>2.608306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.729900</td>\n",
       "      <td>2.631846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.677700</td>\n",
       "      <td>2.584712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.633600</td>\n",
       "      <td>2.651768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.591200</td>\n",
       "      <td>2.589389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.561200</td>\n",
       "      <td>2.633995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.527300</td>\n",
       "      <td>2.450572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.503300</td>\n",
       "      <td>2.490621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.472300</td>\n",
       "      <td>2.536634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.466900</td>\n",
       "      <td>2.461103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.434400</td>\n",
       "      <td>2.513430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.431100</td>\n",
       "      <td>2.489957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.398600</td>\n",
       "      <td>2.429748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.388300</td>\n",
       "      <td>2.465248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.389300</td>\n",
       "      <td>2.285229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.363100</td>\n",
       "      <td>2.437078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.333200</td>\n",
       "      <td>2.354359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.339100</td>\n",
       "      <td>2.433993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.323400</td>\n",
       "      <td>2.379309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.325000</td>\n",
       "      <td>2.270418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.299900</td>\n",
       "      <td>2.286109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.303400</td>\n",
       "      <td>2.320307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.286800</td>\n",
       "      <td>2.281961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.280500</td>\n",
       "      <td>2.298125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.256700</td>\n",
       "      <td>2.350590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.255800</td>\n",
       "      <td>2.358446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.256200</td>\n",
       "      <td>2.334299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.243400</td>\n",
       "      <td>2.239703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.238600</td>\n",
       "      <td>2.358643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.228900</td>\n",
       "      <td>2.305412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.239600</td>\n",
       "      <td>2.219922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.221100</td>\n",
       "      <td>2.253252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.217100</td>\n",
       "      <td>2.260105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.212800</td>\n",
       "      <td>2.217947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>2.195800</td>\n",
       "      <td>2.291800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2.193200</td>\n",
       "      <td>2.133751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.208200</td>\n",
       "      <td>2.325890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.186600</td>\n",
       "      <td>2.318445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>2.193400</td>\n",
       "      <td>2.207477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.188900</td>\n",
       "      <td>2.231425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2.197000</td>\n",
       "      <td>2.204851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.186800</td>\n",
       "      <td>2.248922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.190100</td>\n",
       "      <td>2.225884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2.181000</td>\n",
       "      <td>2.350880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2.179000</td>\n",
       "      <td>2.239120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.172600</td>\n",
       "      <td>2.349676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>2.159400</td>\n",
       "      <td>2.251278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.194400</td>\n",
       "      <td>2.179960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-1000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-1000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-1500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-1500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-2000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-2000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-2500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-2500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-2500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-3000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-3000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-3500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-3500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-4000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-4000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-4000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-4500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-4500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-5000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-5000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-5000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-5500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-5500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-5500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-6000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-6000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-6000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-6500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-6500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-6500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-7000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-7000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-7000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-7500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-7500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-7500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-8000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-8000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-8000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-8500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-8500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-8500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-9000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-9000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-9000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-9500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-9500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-9500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-10000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-10000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-10000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-10500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-10500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-10500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-11000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-11000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-11000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-11500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-11500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-11500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-12000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-12000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-12000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-12500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-12500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-12500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-13000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-13000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-13000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-13500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-13500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-13500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-14000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-14000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-14000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-14500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-14500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-14500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-15000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-15000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-15000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-15500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-15500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-15500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-16000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-16000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-16000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-16500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-16500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-16500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-17000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-17000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-17000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-17500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-17500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-17500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-18000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-18000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-18000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-18500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-18500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-18500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-19000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-19000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-19000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-19500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-19500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-19500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-20000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-20000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-20000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-20500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-20500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-20500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-21000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-21000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-21000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-21500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-21500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-21500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-22000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-22000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-22000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-22500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-22500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-22500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-23000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-23000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-23000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-23500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-23500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-23500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-24000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-24000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-24000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-24500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-24500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-24500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-25000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-25000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-25000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-25500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-25500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-25500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-26000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-26000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-26000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-26500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-26500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-26500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-27000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-27000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-27000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-27500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-27500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-27500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-28000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-28000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-28000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-28500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-28500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-28500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-29000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-29000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-29000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-29500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-29500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-29500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-30000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-30000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-30000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-30500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-30500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-30500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-31000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-31000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-31000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-31500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-31500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-31500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-32000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-32000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-32000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-32500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-32500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-32500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-33000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-33000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-33000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-33500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-33500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-33500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-34000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-34000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-34000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-34500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-34500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-34500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-35000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-35000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-35000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-35500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-35500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-35500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-35500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-36000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-36000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-36000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-36500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-36500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-36500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-36500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-36500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-37000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-37000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-37000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-37500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-37500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-37500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-38000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-38000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-38000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-38000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-38500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-38500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-38500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-38500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-38500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-39000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-39000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-39000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-39500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-39500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-39500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-39500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-39500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-40000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-40000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-40000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-40500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-40500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-40500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-40500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-40500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-41000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-41000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-41000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-41000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-41000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-41500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-41500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-41500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-41500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-41500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-42000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-42000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-42000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-42500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-42500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-42500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-42500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-42500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-43000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-43000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-43000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-43000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-43000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-43500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-43500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-43500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-43500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-43500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-44000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-44000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-44000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-44000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-44000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-44500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-44500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-44500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-44500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-44500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-45000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-45000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-45000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-45500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-45500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-45500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-45500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-45500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-46000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-46000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-46000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-46000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-46000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-46500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-46500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-46500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-46500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-46500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-47000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-47000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-47000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-47000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-47000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-47500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-47500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-47500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-47500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-47500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-48000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-48000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-48000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-48000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-48000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-48500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-48500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-48500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-48500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-48500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-49000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-49000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-49000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-49000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-49000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-49500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-49500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-49500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-49500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-49500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-50000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-50000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-50000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-50500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-50500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-50500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-50500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-50500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-51000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-51000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-51000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-51000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-51000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-51500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-51500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-51500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-51500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-51500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-52000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-52000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-52000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-52000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-52000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-52500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-52500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-52500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-52500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-52500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-53000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-53000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-53000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-53000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-53000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-53500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-53500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-53500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-53500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-53500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-54000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-54000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-54000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-54000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-54000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-54500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-54500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-54500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-54500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-54500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-55000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-55000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-55000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-55500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-55500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-55500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-55500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-55500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-56000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-56000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-56000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-56000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-56000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-56500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-56500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-56500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-56500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-56500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-57000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-57000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-57000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-57000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-57000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-57500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-57500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-57500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-57500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-57500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-58000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-58000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-58000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-58000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-58000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-58500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-58500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-58500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-58500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-58500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-59000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-59000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-59000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-59000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-59000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-59500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-59500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-59500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-59500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-59500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-60000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-60000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-60000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-60500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-60500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-60500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-60500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-60500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-61000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-61000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-61000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-61000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-61000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-61500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-61500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-61500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-61500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-61500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-62000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-62000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-62000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-62000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-62000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-62500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-62500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-62500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-62500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-62500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-63000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-63000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-63000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-63000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-63000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-63500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-63500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-63500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-63500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-63500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-64000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-64000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-64000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-64000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-64000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-64500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-64500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-64500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-64500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-64500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-65000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-65000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-65000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-65500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-65500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-65500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-65500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-65500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-66000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-66000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-66000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-66000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-66000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-66500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-66500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-66500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-66500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-66500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-67000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-67000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-67000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-67000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-67000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-67500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-67500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-67500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-67500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-67500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-68000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-68000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-68000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-68000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-68000/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-68500\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-68500/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-68500/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-68500/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-68500/special_tokens_map.json\n",
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs/checkpoint-69000\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-69000/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-69000/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-69000/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/checkpoint-69000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0. If name, Unnamed: 0.1, verse, verse_idx, Unnamed: 0 are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 536\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=69200, training_loss=2.358364024961615, metrics={'train_runtime': 19954.7868, 'train_samples_per_second': 55.485, 'train_steps_per_second': 3.468, 'total_flos': 3.202048584297907e+16, 'train_loss': 2.358364024961615, 'epoch': 50.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4927275-30b4-4ca9-bf70-a1dd9387a82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to Models/Embibert-finetuned-mBert-50-epochs\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/pytorch_model.bin\n",
      "tokenizer config file saved in Models/Embibert-finetuned-mBert-50-epochs/tokenizer_config.json\n",
      "Special tokens file saved in Models/Embibert-finetuned-mBert-50-epochs/special_tokens_map.json\n",
      "Configuration saved in Models/Embibert-finetuned-mBert-50-epochs/config.json\n",
      "Model weights saved in Models/Embibert-finetuned-mBert-50-epochs/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"Models/Embibert-finetuned-mBert-50-epochs\")\n",
    "model.save_pretrained(\"Models/Embibert-finetuned-mBert-50-epochs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
